### 基于大语言模型的个性化多模态生成
- **关键词**：多模态生成、大语言模型、个性化
- **ACM参考格式**：arXiv:2404.08677v1 [cs.IR] 2024年4月7日
- **作者**：赵晓燕†、朱杰明、肖曦、沈晓腾∗†、张锐∗
- **单位**：华为诺亚方舟实验室（中国深圳）、清华大学深圳国际研究生院（中国深圳）、香港中文大学（中国香港特别行政区）
- **来源**：https://arxiv.org/abs/2404.08677

#### 摘要
大语言模型（LLMs）的出现彻底改变了文本理解和生成的能力。多模态生成引起了工业界和学术界的极大关注，但关于个性化生成的研究较少，而个性化生成在推荐系统等方面具有重要应用。本文提出了首个使用大语言模型进行个性化多模态生成的方法，展示了其应用，并通过在两个数据集上的广泛实验研究验证了其性能。所提出的方法，即个性化多模态生成（简称PMG），首先将用户行为（例如推荐系统中的点击或与虚拟助手的对话）转换为自然语言，以方便大语言模型理解并提取用户偏好描述。然后将这些用户偏好输入到生成器（如多模态大语言模型或扩散模型）中，以生成个性化内容。为了全面且准确地捕捉用户偏好，我们建议让大语言模型输出显式关键词和隐式嵌入的组合来表示用户偏好。然后将关键词和嵌入的组合用作提示，以调节生成器。我们优化了准确率和偏好分数的加权和，使生成的内容在两者之间达到良好的平衡。与没有个性化的基线方法相比，PMG在个性化方面有显著提升，LPIPS最高提升8%，同时保持了生成的准确性。

#### 1. 引言
大语言模型（LLMs）在理解和生成文本方面表现出了令人印象深刻的能力。在这些成就的基础上，研究人员专注于将大语言模型扩展到多模态理解领域，尤其侧重于图像和音频[21, 41]。多模态生成领域也受到了广泛关注，特别是在Sora展示了卓越的视频生成能力之后[23]。为了实现多模态生成任务，大语言模型可以与特定模态的生成器（如扩散模型[14]或多模态大语言模型[22]）相结合。

本文旨在将个性化融入使用大语言模型的多模态生成中，据我们所知，目前尚无现有工作解决此任务。个性化对于提升用户体验和更好地满足用户需求至关重要。图1展示了一个聊天工具的示例。当用户输入“我很开心！”时，聊天工具理解其情感，并自动推荐“开心”的表情符号供用户选择和点击。像TikTok、Discord、微信和Telegram等流行应用已经具备类似功能，但它们没有个性化，如图1左侧所示。添加个性化后，聊天工具将能够生成更吸引用户的个性化表情符号，如图1右侧所示：基于用户的行为历史，如常用表情符号（例如示例中的猫）或历史对话（例如示例中的“我喜欢可爱的猫”），聊天工具将生成开心的猫的表情符号。

多模态生成有广泛的应用。例如，在线广告需要精心设计的产品图像来吸引用户。在推荐电影时，个性化生成器通过放大电影元素以符合用户偏好来生成个性化电影海报，从而更有可能吸引用户的注意力。个性化服装应用可以生成一个人穿着根据其偏好的身高、体重、颜色等定制的服装的图像，以便用户更好地了解穿上后的效果。在视频游戏中，背景音乐可以根据视频内容和用户偏好的音乐类型生成。此外，由于生成的内容反映了用户偏好，它们可以用作数据增强，以提高推荐准确性。

在上述应用中，我们将没有个性化时旨在生成的项目称为目标项目，例如图1左侧的开心表情符号；请注意，可能有多个目标项目，例如有多个笑脸或多个候选推荐电影。我们将有个性化时旨在生成的项目称为个性化目标项目，例如图1右侧的开心表情符号。个性化过程应使候选目标项目根据用户偏好进行调整，同时保持与候选目标项目的相关性，在我们的实验研究中，这种相关性将通过准确率分数来衡量。例如，在图1的示例中，如果我们生成一只哭泣的猫，准确率分数将很低。

为了解决上述应用问题，我们提出了使用大语言模型的个性化多模态生成（简称PMG）。PMG首先从用户的行为历史（如推荐系统中的点击或过去的对话）中提取用户偏好，并将其转换为自然语言，以便大语言模型能够理解。然后将用户偏好输入到生成器（如多模态大语言模型或扩散模型）中，以生成个性化内容。在实现我们的方法时存在一些挑战。

首先，我们发现仅将用户偏好表示为自然语言（特别是关键词）可能不准确，因为它们的表达能力有限，而用户偏好是抽象的。为了解决这个挑战，我们建议让大语言模型输出显式关键词和隐式嵌入的组合来表示用户偏好。然后将关键词和嵌入的组合用作提示，以调节生成器。

其次，调节生成过程也存在挑战，因为它需要准确匹配用户偏好和目标项目。这两个因素的简单混合可能导致不平衡，可能在最终结果中使一个因素盖过另一个因素。为了解决这个问题，我们对每个结果采用准确率分数和偏好分数的加权和。准确率分数衡量生成结果与目标项目之间的一致性程度，而偏好分数则衡量个性化程度。我们通过平衡用户偏好和目标项目的权重来优化总和，从而解决不平衡问题并定制个性化程度。

我们的贡献总结如下：据我们所知，这是第一篇使用大语言模型解决个性化多模态生成问题的工作，我们展示了广泛的应用。

为了解决这个问题，我们提出了一种名为PMG的方法，该方法首先将用户行为转换为自然语言，以便大语言模型能够理解并提取用户偏好。然后将用户偏好输入到生成器中，以生成个性化内容。

为了解决全面准确地捕捉用户偏好的挑战，我们建议让大语言模型输出显式关键词和隐式嵌入的组合来表示用户偏好，然后将其用作提示来调节多模态生成。我们还建议优化准确率分数和偏好分数的加权和，使生成的内容在两者之间达到良好的平衡。

广泛的实验研究验证了我们方法的有效性。与没有个性化的基线方法相比，PMG在个性化方面有显著提升，LPIPS最高提升8%，同时保持了生成的准确性。

#### 2. 相关工作
##### 2.1 多模态生成
在多模态生成领域，先前的研究已经探索了使用生成模型，如生成对抗网络（GANs [11]）和变分自编码器（VAEs [17]），在各种模态中生成多样化和逼真的输出。GANs使用生成器网络和判别器网络进行对抗训练。另一方面，VAEs学习数据的潜在表示并生成新样本。研究人员已经广泛探索和改进了这些方法[4, 12]。

CLIP [25]的引入彻底改变了文本引导生成，使其更易于使用。因此，带有CLIP文本编码器的扩散模型广受欢迎，并成为各种生成任务（包括图像生成[26]和音频生成[38]）的首选方法。它通常在大语言模型响应生成中用作下游多模态生成器。虽然这些方法中的大多数[24, 37]依赖自然语言在预训练的大语言模型和生成器之间建立连接，但它们受到自然语言表达能力有限的限制。相比之下，TANGO [10]和GILL [18]使用信息丰富的隐藏嵌入，但不稳定，需要大量训练来对齐其嵌入空间。

当前的个性化生成方法，如文本反转（Textual Inversion [6]）和DreamBooth [28]，主要侧重于使用少量图像将新角色或图像风格集成到预训练的扩散模型中。这些方法与基于用户行为的个性化有很大不同，后者强调用户的一般兴趣而不是特定实例。此外，用户行为包括点击项目（包括文本和视觉特征）、对话等的组合，使得使用现有个性化生成方法处理起来不切实际。
##### 2.2 大语言模型用于推荐
推荐[29]是信息检索的重要手段，许多研究旨在利用大语言模型的卓越推理能力用于推荐系统。主要方法是利用历史点击序列和候选集中项目的文本特征，以便大语言模型可以直接生成推荐项目。虽然即使不训练也能产生良好结果[7, 15, 32]，但这种方法缺乏对推荐任务的特定优化。某些研究[1, 3, 33]遵循此范例，但使用提示学习[35]或LoRA [16]等技术对大语言模型进行微调，以提高推荐准确性。另一方面，P5 [8]主要使用ID特征而不是文本特征来适应推荐任务。

对于多模态推荐，VIP5 [9]在P5的基础上通过引入项目图像作为视觉特征并引入适配器来理解它们。MISSRec [31]是一种多模态顺序推荐的预训练方法，侧重于学习具有多模态特征的通用项目表示。然而，上述方法仅具有多模态理解能力，而不具备多模态生成能力，即这些方法推荐的项目只有在项目数据库中已有图像时才会有图像；如果一个项目没有可用图像，这些方法在推荐该项目时无法生成图像。

#### 3. 方法
##### 3.1 概述
我们提出的方法PMG如图2所示。我们利用大语言模型的推理能力从历史行为（包括推荐系统中的点击和与虚拟助手的对话）中提取用户偏好。用户行为用于生成偏好条件，包括由冻结的大语言模型生成的自然语言中的显式关键词（称为偏好关键词）和由经过调整的大语言模型生成的用于多模态偏差校正的隐式嵌入（称为软偏好嵌入）[18]。此外，我们将目标项目转换为显式关键词（称为目标项目关键词），以作为目标项目条件。最终，生成器（可以是扩散模型或多模态大语言模型）在其文本编码器之后，通过合并和加权偏好和目标项目条件来生成结果。
##### 3.2 生成显式关键词
鉴于我们使用大语言模型从行为中提取用户偏好的目标，最简单有效的方法是将用户行为转换为文本，并使用大语言模型进行分析。生成器通常具有有限的输入长度（例如，Stable Diffusion [26]中的77个词元），因此关键词总结比使用完整句子更具信息量。因此，我们为每个场景设计提示，并利用大语言模型的零样本能力，无需训练。在下文中，我们将讨论提示设计的过程。
###### 3.2.1 用户行为预处理
我们考虑两种类型的用户行为：历史点击$H = \{h_1, h_2, \cdots\}$和对话$C = \{c_1, c_2, \cdots\}$。输入特征可以是多模态的，包括文本、图像、音频等。通常，大语言模型具有处理复杂文本的能力，因此我们可以简单地将文本输入其中。但是文本可能很长（例如，电影的剧情简介），并且将项目序列中的所有文本连接起来会超过大语言模型的词元长度限制。在这种情况下，我们使用大语言模型将每个项目和对话的文本特征总结为一个简短的句子作为预处理。对于其他特征，我们使用字幕模型（如BLIP - 2 [19]、CLAP [5]）或能够处理多模态输入的多模态大语言模型（如MiniGPT - 4 [41]、mPLUG - owl [39]）将其转换为文本。此预处理的目的是总结特征，减少冗余并保留长期上下文。形式上，此过程可以定义如下：$x_i = [LLM_g(t_{h_i}), LLM_g(v_{h_i}), \cdots]$，$y_i = [LLM_g(t_{c_i}), LLM_g(v_{c_i}), \cdots]$，其中$t$、$v$等是文本、视觉和其他多模态特征，$x_i$和$y_i$表示历史项目和对话的总结数据。$LLM$表示大语言模型的生成操作，与它的前向操作$LLM$区分开来。
###### 3.2.2 提示构建
使用行为信息$x$、$y$，我们可以构建一个提示，借助大语言模型提取用户偏好。还有三个额外的组件：指令原则$p$、属性$a_i$和示例$e$。这些组件是为每个场景人工设计的。原则$p$描述了大语言模型正在执行的任务，即“用户偏好提取”。属性$a$是为每个场景量身定制的，例如“颜色、材料、形状”用于衣服或“类型、导演、产地”用于电影。在每个问题中，大语言模型被分配回答与特定属性相关的用户偏好的任务，然后将答案组合起来。示例$e$提供了期望的输出格式和示例关键词（例如，“可爱”、“卡通”等），不仅有助于指导大语言模型的响应，还遵循标准化的输出格式，从而便于从生成的输出中提取关键词。使用此提示，我们可以将大语言模型为属性$a_i$生成的关键词$k_i^p$表示如下：$k_i^p = LLM_g(p, a_i, e, x, y)$。接下来，我们组合每个属性的输出并消除任何重复项，以获得偏好关键词$k^p$。生成目标项目关键词$k^t$的过程类似，但只有一个目标项目$h^t$及其相应的总结信息$x^t$。在这种情况下，不涉及对话，并且只有一个整体属性（上述所有属性的并集）：$k^t = LLM_g(p, e, x^t)$。
##### 3.3 生成软偏好嵌入
我们已经开发了一种仅依赖显式关键词进行表示的方法。然而，自然语言作为一种离散形式，表达能力有限且长度有限。另一方面，利用连续隐藏嵌入，它提供了更丰富和精确的表示，但需要大量的训练资源。我们以自然语言为基线，同时训练软偏好嵌入作为额外信号，借助大语言模型纠正这种语言偏差，称为偏差校正大语言模型。这些嵌入有助于解决自然语言基线与实际用户兴趣之间的不匹配问题。该模型如图3所示。
###### 3.3.1 偏差校正大语言模型
大语言模型的主要目标是预测下一个文本词元，因此它只能理解和生成文本。然而，当应用于多模态生成时，有必要引入多模态词元以获得多模态生成能力。受GILL[18]的启发，我们将多模态词元作为可学习参数纳入嵌入表，然后使用线性层对齐大语言模型与生成器的嵌入空间。这种对齐确保了大语言模型与生成器的文本编码器之间的一致性和兼容性，促进了生成过程。此外，我们采用P - Tuning V2 [20]对大语言模型进行微调，专门用于生成任务，这可以增强其生成能力。在每次推理时，多模态词元在用户行为提示之后添加。软偏好嵌入是通过将这些增强的输入通过（带有P - Tuning V2的）大语言模型和线性层获得的。

形式上，结合在3.2节中构建的用户行为提示$p$、$x$、$y$，我们包括额外的长度为$L$的多模态词元$m = \{m_1, \cdots, m_L\}$。在这种情况下，属性和示例不被使用，因为前缀嵌入有能力自己学习它们。这些词元被传递给大语言模型，并且它们在嵌入层中的相应嵌入是可训练的。按照P - Tuning V2方法，$S$个可训练的前缀嵌入$t = \{t_1, \cdots, t_S\}$在每个变压器层的自注意力中被添加到嵌入序列之前。大语言模型前向操作中的结果输出嵌入可以表示为：$prompt = (p, x, y)$，$[E_{prompt}, E_m] = LLM_f(t, prompt, m)$，其中$E_{prompt}$、$E_m$表示大语言模型的输出嵌入，软偏好嵌入$E_m$用于后续的多模态生成过程。
###### 3.3.2 多模态监督训练
与仅依赖字幕进行监督的GILL [18]不同，我们认为引入多模态监督（如真实图像或音频）更有意义，有助于纠正偏差。然而，这种方法引入了通过生成器反向传播梯度的挑战，导致训练难度增加。为了简化训练，我们利用3.2节中生成的偏好关键词作为基础框架，并专注于训练有限数量的软偏好嵌入作为生成过程的额外条件。

偏好关键词被分词并由生成器的文本编码器转换为硬偏好嵌入$E_k$。然后，我们将$E_m$和$E_k$连接起来作为生成器的条件输入。关于数据分割，由于不可能获得真实的个性化图像作为真实标签，我们使用交互序列中的最后一个项目作为监督，其他项目作为输入。

超参数$\alpha$通常为0.5，可以根据使用场景和需求进行调整以实现不同的效果。

不同的生成器模型有不同的训练算法。在我们的实现中，我们使用扩散模型，它包含一个文本编码器和一个U - Net [27]。U - Net用作条件去噪模块，通过多个去噪步骤生成图像。按照其训练过程，我们向多模态监督$M_s$引入随机噪声$\epsilon \sim N(0, 1)$，然后尝试对其进行去噪：$E^p = concatenate(E_m, E_k)$，$M_n = M_s + \epsilon$，$M_d = Unet(E^p, M_n)$。损失计算为$M_s$和$M_d$的均方误差（MSE）损失：$loss = MSE(M_s, M_d)$。使用此损失，我们训练多模态词元的嵌入以及P - Tuning V2中的前缀嵌入，以实现大语言模型的多模态生成能力，同时训练映射层以对齐嵌入空间。
##### 3.4 平衡准确率分数和偏好分数
与仅包含偏好条件的软偏好嵌入训练过程不同，生成推理过程同时包含偏好和目标项目条件。简单地组合这些条件可能导致对其中一个的偏向，从而掩盖另一个。遵循先前的研究，如DreamBooth [28]和GILL [18]，我们使用生成结果与偏好关键词之间的相似度来衡量个性化程度，我们称之为偏好分数，而准确率分数是指与目标项目关键词的相似度。准确率分数衡量与目标项目的一致性程度，而偏好分数关于偏好条件衡量个性化程度。为了平衡它们，我们使用预训练的多模态网络（如CLIP [25]、CLAP [5]）对准确率分数和偏好分数进行加权求和。假设多模态结果$M$由以下方式生成：$M = Generator(w_p \cdot E^p, w_t \cdot E^t)$，其中$w_p$、$w_t$是要调整的偏好和目标项目条件的权重。通过预训练多模态网络的编码器，我们可以将结果$M$和关键词$k^P$、$k^t$转换为嵌入$e_M$、$e_p$、$e_t$。然后我们可以计算它们之间的相似度作为偏好分数$d_p$和准确率分数$d_t$：$d_p=\frac{e_M \cdot e_p}{\left\lVert e_M\right\rVert _{2}\left\lVert e_p\right\rVert _{2}}$，$d_t=\frac{e_M \cdot e_t}{\left\lVert e_M\right\rVert _{2}\left\lVert e_t\right\rVert _{2}}$。最后，我们的目标是优化$d_p$和$d_t$的加权和：$z=\alpha \cdot \log d_p+(1-\alpha) \cdot \log d_t$。

考虑到当前多模态生成器强大的并行生成能力，我们使用多个预定义的权重集$w_p$、$w_t$进行生成，并选择得分$z$最高的一个。

#### 4. 实验
我们的方法可用于生成各种多模态内容，不仅包括图像和音频，还包括其他模态。在本节中，我们专注于图像生成，因为它被认为是最常见和直观的模态。请参阅附录A以获取代码和实现细节。我们的实验旨在回答以下研究问题：
- **RQ1**：PMG能否准确生成结合用户偏好的图像？
- **RQ2**：为什么条件加权是必要的？
- **RQ3**：显式关键词和隐式嵌入如何影响性能？
- **RQ4**：在训练软偏好嵌入时，P - Tuning V2和多模态词元是否有益？
- **RQ5**：生成的图像除了用于用户展示之外，是否还有其他目的或应用？
##### 4.1 实验设置
###### 4.1.1 场景和数据集
我们设计了以下三个场景来验证我们的方法：
        - 根据用户历史点击的产品生成缺少原始图像的产品的个性化图像。我们采用POG [2]，一个时尚服装的多模态数据集，用于训练和评估。我们选择了2000名用户和16100个项目进行实验。
        - 根据用户历史观看的电影生成电影的个性化海报。我们采用小型MovieLens最新数据集[13]，其中包含9000部电影、600名用户和100000次评分交互。
        - 根据用户当前对话和历史使用的表情符号生成即时通讯中的表情符号。由于我们找不到合适的数据集，我们不训练软偏好嵌入，仅使用关键词生成图像。

这些数据集本身不包括对话，因此我们设计了一些模板来构建它们。
###### 4.1.2 评估指标
我们使用多个图像相似度指标来评估生成图像与历史/目标项目之间的相似性，量化实现的视觉个性化程度。为了防止潜在的信息泄漏，我们在评估中排除了加权模块中使用的CLIP指标。相反，我们使用以下两个指标：
        - LPIPS（学习到的感知图像块相似度）[40]：该指标通过考虑人类视觉感知来衡量两幅图像之间的感知相似度。它侧重于捕捉语义信息。
        - SSIM（结构相似性指数度量）[34]：广泛用于图像相似性评估，该指标考虑亮度、对比度和结构信息。它更侧重于图像质量。

通过使用这些指标，我们可以全面评估生成图像与历史/目标项目之间的视觉相似性，从而深入了解我们的个性化生成方法的有效性。此外，我们还进行了人工评估，以在现实世界中验证其有效性。
##### 4.2 图像比较（RQ1）
在本节中，我们展示了在三个场景（服装场景、电影海报场景和表情符号场景）中生成的图像。现有的个性化生成方法，如文本反转[6]和DreamBooth [28]，为每个用户使用其历史项目图像训练额外的嵌入。它们仅适用于用户数量较少的场景，因为它们可能消耗大量的训练资源。因此，在我们的实验中，它们未被用作基线方法。

在服装场景（图4）中，PMG展示出了显著的个性化能力，特别是在卡通和女孩风格方面。在卡通风格中，PMG识别出这些项目与特定卡通角色的关联，并相应地选择卡通熊作为生成输出。在女孩风格中，PMG融入了许多符合女孩偏好的花卉图案。

在电影海报场景（图5）中，PMG巧妙地将用户偏好与目标项目相结合。例如，对于惊悚电影《真实犯罪》，PMG始终将犯罪和恐怖元素融入生成的海报中，无论由哪个用户生成。对于浪漫电影《泰坦尼克号》，生成的海报始终以一对相爱的情侣为特色，而风格则根据用户偏好而有所不同。

在表情符号场景（图6）中，我们根据当前对话和先前使用的表情符号生成表情符号。利用历史表情符号，大语言模型帮助总结用户的偏好，并设计像猫或踢足球的男孩这样的卡通角色。然后，大语言模型分析对话以识别其情感，并为表情符号设计合适的姿势，如悲伤哭泣或疲劳眯眼。最后，角色和姿势可以分别被视为偏好条件和目标条件，以生成最终的表情符号。因此，我们为动物爱好者生成以猫为特色的表情符号，为体育爱好者生成与球相关的表情符号等，并且传达的情感通常是准确的。

然而，PMG无法生成与真实实体一致的图像。例如，生成的电影海报中的角色可能与真实演员不匹配，服装可能与真实产品不匹配。我们将在未来的工作中讨论并改进这一点。
##### 4.3 人工评估（RQ1）
基于图像相似度指标的图像比较展示了生成图像的个性化，但无法确定它们在现实世界场景中是否能吸引用户。为了解决这个问题，我们进行了人工评估，以比较我们的方法PMG、文本反转[6]生成的图像和没有个性化的图像。在文本反转中，我们仅使用历史点击项目的图像来学习用户偏好。我们邀请了40名志愿者对60张图像（每种类型20张）从1到3进行评分（分数越高表示结果越好）。志愿者给出的平均分数如表1所示。

从人工评估结果中我们可以看出，我们基于多模态用户行为的方法PMG优于仅基于历史点击图像的文本反转。人工评估验证了PMG的有效性。
##### 4.4 案例研究（RQ2）
如3.4节所述，直接组合个性化和目标条件可能导致不平衡。在图7中，我们观察到在调整浪漫目标电影《泰坦尼克号》和灾难爱好者的条件权重时生成海报的变化。当条件权重设置为$w_p:w_t = 0:4$时，海报主要考虑目标条件（浪漫），描绘了一对相爱的情侣。相反，当权重调整为$w_p:w_t = 4:0$时，海报仅关注偏好条件（灾难），描绘了一艘在风暴中的船。

为了在遵循我们在公式1中概述的选择原则的同时结合浪漫和灾难元素，我们根据生成海报的$z$分数对其进行评估。图7b实现了最高的$z$分数，并被选为最终输出。
##### 4.5消融研究
###### 4.5.1偏好条件（RQ3）
在本节中，我们研究了两种用户偏好表示形式（偏好关键词和软偏好嵌入）的贡献（表2）。通过计算生成图像与历史项目之间的相似度，我们可以衡量个性化程度，通过计算与目标项目的相似度，我们可以确保我们的生成不会偏离目标。

我们的方法结合了用户偏好（反映在历史项目中），令人惊讶的是，在电影场景中与目标项目的相似度甚至增加了。这表明个性化可以消除生成器与真实场景之间的误差。关键词在LPIPS和SSIM指标中都大大提高了相似度，而软偏好嵌入降低了LPIPS但不影响SSIM。这表明嵌入引入了个性化语义信息，但由于不稳定性并未提高图像质量。通过结合偏好关键词和软偏好嵌入，我们在不偏离目标项目的情况下实现了丰富的个性化内容，同时确保了图像质量。

图8是关于软偏好嵌入的案例研究。当仅提供关键词“鞋子，卡通”时，有一定概率生成卡通风格的鞋子绘图。然而，在纳入软偏好嵌入后，模型始终生成带有卡通图案的真实鞋子。
###### 4.5.2 提示调整（RQ4）
在本节中，我们分析P - Tuning V2和多模态词元对个性化程度（通过生成图像与历史项目之间的LPIPS相似度衡量）的影响。表3展示了它们的有效性。P - Tuning V2极大地增强了大语言模型提取用户偏好的能力。同样，多模态词元也表现出积极影响，尽管它们也占用了有限的条件嵌入并减少了有效关键词的数量。因此，多模态词元的数量不应太大，将$L = 4$或$L = 8$确定为最佳参数。
##### 4.6 辅助生成（RQ5）
我们的方法广泛探索了使用大语言模型进行兴趣建模，使生成的图像不仅可用于向用户展示，还可用于下游推荐任务。本节介绍了在MovieLens上进行的一项实验，旨在评估将生成的图像作为额外视觉特征纳入的影响。为了进行评估，我们使用MMGCN [36]作为基础多模态推荐模型。

MovieLens数据集本身包含项目的图像特征，即原始电影海报，但缺少用户的图像特征。因此，我们设计了以下实验：（1）无图像：此实验不使用任何图像特征，仅依赖项目和用户的ID。（2）仅项目：此实验仅使用项目的图像特征。（3）平均用户：除了项目图像特征外，用户图像特征初始化为历史观看项目的平均值。（4）生成用户：除了项目图像特征外，用户图像特征初始化为PMG生成的图像。需要注意的是，生成的图像是在偏好条件下创建的，没有目标项目。

表4提供了有力证据，表明纳入项目或用户的图像特征显著提高了推荐准确性。值得注意的是，纳入PMG生成的图像比简单平均基线产生了更好的结果。这些发现强调了我们的方法通过利用大语言模型的推理能力有效捕捉用户兴趣的能力。通过纳入生成的图像，我们的方法成功捕捉并纳入了微妙的用户偏好，从而提高了推荐性能。

#### 5. 结论与进一步工作
在本文中，我们提出了一种名为PMG的方法，用于使用大语言模型进行个性化多模态生成。通过利用大语言模型，我们提取了用户偏好，并将其用于调节生成器的生成过程。图像生成实验验证了PMG的有效性及其在下游推荐任务中的潜力。这项工作为个性化生成的进一步发展铺平了道路，能够创建量身定制且引人入胜的用户体验。

在未来的工作中，我们旨在提高生成图像的真实感。我们计划采用基于检索的增强方法，通过纳入真实图像输入作为参考，以指导生成更真实的图像，解决幻觉问题。
